{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Importing Libraries "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import os\n",
    "\n",
    "# HOST = \"http://localhost:5000\"\n",
    "HOST = \"http://127.0.0.1:5000\"\n",
    "\n",
    "\n",
    "PROJECT_NAME = \"CustomerChurn\"\n",
    "EXPERIMENT_NAME = \"TFlowSaeed02\"\n",
    "\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL']='http://localhost:9000'\n",
    "os.environ['AWS_ACCESS_KEY_ID']='AKIAIOSFODNN7EXAMPLE'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY']='wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'\n",
    "os.environ['AWS_REGION']='us-east-1'\n",
    "os.environ['AWS_BUCKET_NAME']='mlflow'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Do the hyper parameter initializing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "directory = \"/Users/skasmani/Downloads/Redhat/codes/dataset/time series dataset/\"\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "lr = 0.01"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Load the dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now load the dataset into a pandas data frame."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df=pd.read_csv(directory +'household_power_consumption.txt', sep=';', header=0, low_memory=False, infer_datetime_format=True, parse_dates={'datetime':[0,1]}, index_col=['datetime'])\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.840</td>\n",
       "      <td>18.400</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.630</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.290</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.740</td>\n",
       "      <td>23.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.680</td>\n",
       "      <td>15.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Global_active_power Global_reactive_power  Voltage  \\\n",
       "datetime                                                                 \n",
       "2006-12-16 17:24:00               4.216                 0.418  234.840   \n",
       "2006-12-16 17:25:00               5.360                 0.436  233.630   \n",
       "2006-12-16 17:26:00               5.374                 0.498  233.290   \n",
       "2006-12-16 17:27:00               5.388                 0.502  233.740   \n",
       "2006-12-16 17:28:00               3.666                 0.528  235.680   \n",
       "\n",
       "                    Global_intensity Sub_metering_1 Sub_metering_2  \\\n",
       "datetime                                                             \n",
       "2006-12-16 17:24:00           18.400          0.000          1.000   \n",
       "2006-12-16 17:25:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:26:00           23.000          0.000          2.000   \n",
       "2006-12-16 17:27:00           23.000          0.000          1.000   \n",
       "2006-12-16 17:28:00           15.800          0.000          1.000   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "datetime                             \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imputing Null Values "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "df = df.replace('?', np.nan)\n",
    "df.isnull().sum()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Global_active_power      25979\n",
       "Global_reactive_power    25979\n",
       "Voltage                  25979\n",
       "Global_intensity         25979\n",
       "Sub_metering_1           25979\n",
       "Sub_metering_2           25979\n",
       "Sub_metering_3           25979\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we will create a function that will impute missing values by replacing them with values on their previous day."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def fill_missing(values):\n",
    "    one_day = 60*24\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            if np.isnan(values[row][col]):\n",
    "                values[row,col] = values[row-one_day,col]\n",
    "df = df.astype('float32')\n",
    "fill_missing(df.values)\n",
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Global_active_power      0\n",
       "Global_reactive_power    0\n",
       "Voltage                  0\n",
       "Global_intensity         0\n",
       "Sub_metering_1           0\n",
       "Sub_metering_2           0\n",
       "Sub_metering_3           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Downsampling of Data from minutes to Days\n",
    "\n",
    "### There are more than 2 lakh observations recorded. Letâ€™s make the data simpler by downsampling them from the frequency of minutes to days."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "daily_df = df.resample('D').sum()\n",
    "daily_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16</th>\n",
       "      <td>1209.176025</td>\n",
       "      <td>34.922001</td>\n",
       "      <td>93552.53125</td>\n",
       "      <td>5180.799805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>4926.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-17</th>\n",
       "      <td>3390.459961</td>\n",
       "      <td>226.005997</td>\n",
       "      <td>345725.31250</td>\n",
       "      <td>14398.599609</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>4187.0</td>\n",
       "      <td>13341.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-18</th>\n",
       "      <td>2203.825928</td>\n",
       "      <td>161.792007</td>\n",
       "      <td>347373.62500</td>\n",
       "      <td>9247.200195</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>14018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-19</th>\n",
       "      <td>1666.193970</td>\n",
       "      <td>150.942001</td>\n",
       "      <td>348479.00000</td>\n",
       "      <td>7094.000000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>7602.0</td>\n",
       "      <td>6197.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-20</th>\n",
       "      <td>2225.748047</td>\n",
       "      <td>160.998001</td>\n",
       "      <td>348923.62500</td>\n",
       "      <td>9313.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2648.0</td>\n",
       "      <td>14063.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Global_active_power  Global_reactive_power       Voltage  \\\n",
       "datetime                                                               \n",
       "2006-12-16          1209.176025              34.922001   93552.53125   \n",
       "2006-12-17          3390.459961             226.005997  345725.31250   \n",
       "2006-12-18          2203.825928             161.792007  347373.62500   \n",
       "2006-12-19          1666.193970             150.942001  348479.00000   \n",
       "2006-12-20          2225.748047             160.998001  348923.62500   \n",
       "\n",
       "            Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
       "datetime                                                                      \n",
       "2006-12-16       5180.799805             0.0           546.0          4926.0  \n",
       "2006-12-17      14398.599609          2033.0          4187.0         13341.0  \n",
       "2006-12-18       9247.200195          1063.0          2621.0         14018.0  \n",
       "2006-12-19       7094.000000           839.0          7602.0          6197.0  \n",
       "2006-12-20       9313.000000             0.0          2648.0         14063.0  "
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train â€“ Test Split\n",
    "### After downsampling, the number of instances is 1442. We will split the dataset into train and test data in a 75% and 25% ratio of the instances. (0.75 * 1442 = 1081)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_df,test_df = daily_df[1:1081], daily_df[1081:] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaling the values \n",
    "\n",
    "#### All the columns in the data frame are on a different scale. Now we will scale the values to -1 to 1 for faster training of the models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "train = train_df\n",
    "scalers={}\n",
    "for i in train_df.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    s_s = scaler.fit_transform(train[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    train[i]=s_s\n",
    "test = test_df\n",
    "for i in train_df.columns:\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    s_s = scaler.transform(test[i].values.reshape(-1,1))\n",
    "    s_s=np.reshape(s_s,len(s_s))\n",
    "    scalers['scaler_'+i] = scaler\n",
    "    test[i]=s_s"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n",
      "/var/folders/bc/2l89x1hs7f5c0gv5q2_lj11r0000gn/T/ipykernel_71532/3151536076.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[i]=s_s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Converting the series to samples \n",
    "\n",
    "Now we will make a function that will use a sliding window approach to transform our series into samples of input past observations and output future observations to use supervised learning algorithms."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "      #\n",
    "  # n_past ==> no of past observations\n",
    "  #\n",
    "  # n_future ==> no of future observations \n",
    "  #\n",
    "  X, y = list(), list()\n",
    "  for window_start in range(len(series)):\n",
    "    past_end = window_start + n_past\n",
    "    future_end = past_end + n_future\n",
    "    if future_end > len(series):\n",
    "      break\n",
    "    # slicing the past and future parts of the window\n",
    "    past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "    X.append(past)\n",
    "    y.append(future)\n",
    "  return np.array(X), np.array(y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this case, letâ€™s assume that given the past 10 days observation, we need to forecast the next 5 days observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "n_past = 10\n",
    "n_future = 5 \n",
    "n_features = 7"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now convert both the train and test data into samples using the split_series function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "X_train, y_train = split_series(train.values,n_past, n_future)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))\n",
    "X_test, y_test = split_series(test.values,n_past, n_future)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],n_features))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1], n_features))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Architecture\n",
    "Now we will create two models in the below-mentioned architecture.\n",
    "### E1D1  ==> Sequence to Sequence Model with one encoder layer and one decoder layer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# E1D1\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs1[0])\n",
    "\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_outputs1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l1)\n",
    "\n",
    "#\n",
    "model_e1d1 = tf.keras.models.Model(encoder_inputs,decoder_outputs1)\n",
    "\n",
    "#\n",
    "model_e1d1.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: AMD Radeon Pro 555X\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 2.00 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 10:49:46.471511: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-28 10:49:46.479296: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-09-28 10:49:46.480278: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 43200       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 5, 100)       0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 5, 100)       80400       repeat_vector[0][0]              \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 5, 7)         707         lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 124,307\n",
      "Trainable params: 124,307\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### E2D2 ==> Sequence to Sequence Model with two encoder layers and two decoder layers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# E2D2\n",
    "# n_features ==> no of features at each timestep in the data.\n",
    "#\n",
    "encoder_inputs = tf.keras.layers.Input(shape=(n_past, n_features))\n",
    "encoder_l1 = tf.keras.layers.LSTM(100,return_sequences = True, return_state=True)\n",
    "encoder_outputs1 = encoder_l1(encoder_inputs)\n",
    "encoder_states1 = encoder_outputs1[1:]\n",
    "encoder_l2 = tf.keras.layers.LSTM(100, return_state=True)\n",
    "encoder_outputs2 = encoder_l2(encoder_outputs1[0])\n",
    "encoder_states2 = encoder_outputs2[1:]\n",
    "#\n",
    "decoder_inputs = tf.keras.layers.RepeatVector(n_future)(encoder_outputs2[0])\n",
    "#\n",
    "decoder_l1 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_inputs,initial_state = encoder_states1)\n",
    "decoder_l2 = tf.keras.layers.LSTM(100, return_sequences=True)(decoder_l1,initial_state = encoder_states2)\n",
    "decoder_outputs2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(n_features))(decoder_l2)\n",
    "#\n",
    "model_e2d2 = tf.keras.models.Model(encoder_inputs,decoder_outputs2)\n",
    "#\n",
    "model_e2d2.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 10, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 10, 100), (N 43200       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 100), (None, 80400       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 5, 100)       0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 5, 100)       80400       repeat_vector_1[0][0]            \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 5, 100)       80400       lstm_4[0][0]                     \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 5, 7)         707         lstm_5[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 285,107\n",
      "Trainable params: 285,107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the models\n",
    "\n",
    "I have used Adam optimizer and Huber loss as the loss function.  Letâ€™s compile and run the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "reduce_lr = tf.keras.callbacks.LearningRateScheduler(lambda x: 1e-3 * 0.90 ** x)\n",
    "model_e1d1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e1d1=model_e1d1.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])\n",
    "model_e2d2.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.Huber())\n",
    "history_e2d2=model_e2d2.fit(X_train,y_train,epochs=25,validation_data=(X_test,y_test),batch_size=32,verbose=0,callbacks=[reduce_lr])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 10:49:48.677390: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-09-28 10:49:50.624180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:49:50.927010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:49:52.002819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:49:53.834275: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:49:56.746241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:49:59.932117: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:00.023366: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:00.113800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:53.356114: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:53.798918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:53.882028: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:53.968821: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:54.046039: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:54.183090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:54.331257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:54.479861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:54.633765: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:59.603166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:59.777078: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:59.887967: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:50:59.986594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:51:00.066747: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prediction on test samples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "pred_e1d1=model_e1d1.predict(X_test)\n",
    "pred_e2d2=model_e2d2.predict(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-28 10:52:52.006732: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:52.113069: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:52.282997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:53.746286: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:53.908193: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:54.031011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:54.162336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-09-28 10:52:54.266152: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inverse Scaling of the predicted values\n",
    "\n",
    "Now we will convert the predictions to their original scale."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for index,i in enumerate(train_df.columns):\n",
    "    scaler = scalers['scaler_'+i]\n",
    "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    pred_e1d1[:,:,index]=scaler.inverse_transform(pred_e1d1[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    pred_e2d2[:,:,index]=scaler.inverse_transform(pred_e2d2[:,:,index])\n",
    "    y_train[:,:,index]=scaler.inverse_transform(y_train[:,:,index])\n",
    "    y_test[:,:,index]=scaler.inverse_transform(y_test[:,:,index])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking Error\n",
    "\n",
    "Now we will calculate the mean absolute error of all observations."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "for index,i in enumerate(train_df.columns):\n",
    "  print(i)\n",
    "  for j in range(1,6):\n",
    "    print(\"Day \",j,\":\")\n",
    "    print(\"MAE-E1D1 : \",mean_absolute_error(y_test[:,j-1,index],pred_e1d1[:,j-1,index]),end=\", \")\n",
    "    print(\"MAE-E2D2 : \",mean_absolute_error(y_test[:,j-1,index],pred_e2d2[:,j-1,index]))\n",
    "  print()\n",
    "  print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Global_active_power\n",
      "Day  1 :\n",
      "MAE-E1D1 :  3428148.5, MAE-E2D2 :  3570131.2\n",
      "Day  2 :\n",
      "MAE-E1D1 :  3430778.5, MAE-E2D2 :  3416139.2\n",
      "Day  3 :\n",
      "MAE-E1D1 :  3412765.5, MAE-E2D2 :  3479636.8\n",
      "Day  4 :\n",
      "MAE-E1D1 :  3403679.2, MAE-E2D2 :  3527938.2\n",
      "Day  5 :\n",
      "MAE-E1D1 :  3392096.2, MAE-E2D2 :  3531549.5\n",
      "\n",
      "\n",
      "Global_reactive_power\n",
      "Day  1 :\n",
      "MAE-E1D1 :  31146.346, MAE-E2D2 :  30501.965\n",
      "Day  2 :\n",
      "MAE-E1D1 :  31507.42, MAE-E2D2 :  31858.902\n",
      "Day  3 :\n",
      "MAE-E1D1 :  31422.375, MAE-E2D2 :  31734.877\n",
      "Day  4 :\n",
      "MAE-E1D1 :  31320.79, MAE-E2D2 :  31641.219\n",
      "Day  5 :\n",
      "MAE-E1D1 :  31229.51, MAE-E2D2 :  31921.787\n",
      "\n",
      "\n",
      "Voltage\n",
      "Day  1 :\n",
      "MAE-E1D1 :  3747129300.0, MAE-E2D2 :  3742625300.0\n",
      "Day  2 :\n",
      "MAE-E1D1 :  3746351400.0, MAE-E2D2 :  3747049000.0\n",
      "Day  3 :\n",
      "MAE-E1D1 :  3744909600.0, MAE-E2D2 :  3745716200.0\n",
      "Day  4 :\n",
      "MAE-E1D1 :  3743784200.0, MAE-E2D2 :  3742480600.0\n",
      "Day  5 :\n",
      "MAE-E1D1 :  3743289300.0, MAE-E2D2 :  3740523800.0\n",
      "\n",
      "\n",
      "Global_intensity\n",
      "Day  1 :\n",
      "MAE-E1D1 :  61159796.0, MAE-E2D2 :  62973180.0\n",
      "Day  2 :\n",
      "MAE-E1D1 :  60501864.0, MAE-E2D2 :  61589268.0\n",
      "Day  3 :\n",
      "MAE-E1D1 :  59958310.0, MAE-E2D2 :  60297176.0\n",
      "Day  4 :\n",
      "MAE-E1D1 :  59802084.0, MAE-E2D2 :  60489496.0\n",
      "Day  5 :\n",
      "MAE-E1D1 :  59771412.0, MAE-E2D2 :  61514624.0\n",
      "\n",
      "\n",
      "Sub_metering_1\n",
      "Day  1 :\n",
      "MAE-E1D1 :  8667772.0, MAE-E2D2 :  8768010.0\n",
      "Day  2 :\n",
      "MAE-E1D1 :  8836944.0, MAE-E2D2 :  8880917.0\n",
      "Day  3 :\n",
      "MAE-E1D1 :  8861359.0, MAE-E2D2 :  9008091.0\n",
      "Day  4 :\n",
      "MAE-E1D1 :  8902942.0, MAE-E2D2 :  8865144.0\n",
      "Day  5 :\n",
      "MAE-E1D1 :  8945163.0, MAE-E2D2 :  8747090.0\n",
      "\n",
      "\n",
      "Sub_metering_2\n",
      "Day  1 :\n",
      "MAE-E1D1 :  9670317.0, MAE-E2D2 :  7982282.0\n",
      "Day  2 :\n",
      "MAE-E1D1 :  9427865.0, MAE-E2D2 :  9392304.0\n",
      "Day  3 :\n",
      "MAE-E1D1 :  9200591.0, MAE-E2D2 :  10175185.0\n",
      "Day  4 :\n",
      "MAE-E1D1 :  9162052.0, MAE-E2D2 :  10359987.0\n",
      "Day  5 :\n",
      "MAE-E1D1 :  9166155.0, MAE-E2D2 :  10132427.0\n",
      "\n",
      "\n",
      "Sub_metering_3\n",
      "Day  1 :\n",
      "MAE-E1D1 :  87307280.0, MAE-E2D2 :  89183750.0\n",
      "Day  2 :\n",
      "MAE-E1D1 :  88868180.0, MAE-E2D2 :  87480950.0\n",
      "Day  3 :\n",
      "MAE-E1D1 :  88824500.0, MAE-E2D2 :  86656510.0\n",
      "Day  4 :\n",
      "MAE-E1D1 :  88646250.0, MAE-E2D2 :  87070080.0\n",
      "Day  5 :\n",
      "MAE-E1D1 :  88669016.0, MAE-E2D2 :  88575470.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "\n",
    "\n",
    "# Connect to local MLflow tracking server\n",
    "mlflow.set_tracking_uri(HOST)\n",
    "\n",
    "# Set the experiment name...\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# _original_keras_log_model = mlflow.keras.log_model\n",
    "\n",
    "# def _keras_log_model_patch(*args, **kwargs):\n",
    "#     kwargs[\"save_format\"] = \"tf\"\n",
    "#     _original_keras_log_model(*args, **kwargs)\n",
    "\n",
    "# mlflow.keras.log_model = _keras_log_model_patch\n",
    "\n",
    "\n",
    "\n",
    "# mlflow.tensorflow.autolog(every_n_iter=1)\n",
    "mlflow.keras.autolog()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('AI_ML_38_GPU': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "10d220c55dad87bc296f91a276cffc08c658df4f112171a2982baf6251a25e4e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}